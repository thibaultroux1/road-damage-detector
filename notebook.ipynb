{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "38a60c5991e2a49fcb728a4f0b42df6d6302cdd4a358ff20b733caefebd4e3da"
    },
    "colab": {
      "name": "download.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download datasets"
      ],
      "metadata": {
        "id": "UUXYHKUNaYT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2018 Dataset"
      ],
      "metadata": {
        "id": "-R2IFwLkaYUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the two following cells are not working, you can download the dataset [here](https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/Japan/CACAIE2018/RoadDamageDataset.tar.gz) and extract it."
      ],
      "metadata": {
        "id": "yxysdmCCaYUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import urllib.request\r\n",
        "\r\n",
        "print('Downloading the 2018 GRDDC Dataset (1.7 GB) ...')\r\n",
        "\r\n",
        "url = 'https://mycityreport.s3-ap-northeast-1.amazonaws.com/02_RoadDamageDataset/public_data/Japan/CACAIE2018/RoadDamageDataset.tar.gz'\r\n",
        "urllib.request.urlretrieve(url, 'RDD_Dataset_2018.tar.gz')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrtbSMHAaYUC",
        "outputId": "692675dd-af2d-484c-ca16-77c812309800"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Extracting file ...\\n')\r\n",
        "!tar -zxf 'RDD_Dataset_2018.tar.gz'\r\n",
        "!mv RoadDamageDataset RDD_Dataset_2018\r\n",
        "print('Extraction done !\\n')\r\n",
        "!rm RDD_Dataset_2018.tar.gz\r\n",
        "print('RDD_Dataset_2018.tar.gz removed.')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWyEHj4YaYUD",
        "outputId": "013d46b2-f9ca-450d-ab68-b5f49b765cd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2020 Dataset"
      ],
      "metadata": {
        "id": "AHdtPal7aYUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the two following cells are not working, you can download the dataset [here](https://md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com/7b38c0a4-9c9a-4aa7-8c45-290b70c36262) and extract it."
      ],
      "metadata": {
        "id": "OI_P8FtBaYUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import urllib.request\r\n",
        "\r\n",
        "print('Downloading the 2020 GRDDC Dataset (1.1 GB)')\r\n",
        "\r\n",
        "url = 'https://md-datasets-public-files-prod.s3.eu-west-1.amazonaws.com/7b38c0a4-9c9a-4aa7-8c45-290b70c36262'\r\n",
        "urllib.request.urlretrieve(url, 'RDD_Dataset_2020.tar.gz')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f9ENkxKaYUE",
        "outputId": "7e5f4edb-cc87-45e6-946a-d3dadeff08e3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print('Extracting file ...\\n')\r\n",
        "!tar -zxf 'RDD_Dataset_2020.tar.gz'\r\n",
        "!mv train RDD_Dataset_2020\r\n",
        "print('Extraction done !\\n')\r\n",
        "!rm RDD_Dataset_2020.tar.gz\r\n",
        "print('RDD_Dataset_2020.tar.gz removed.')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fudY8X5uaYUF",
        "outputId": "623915f0-0914-4364-ddeb-48bb18efe833"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modify the architecture of the datasets as well as the label format to be compatible with YoloV5"
      ],
      "metadata": {
        "id": "BFoPpbrsa36E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "mIa4mdgWboQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from xml.etree import ElementTree\r\n",
        "from xml.dom import minidom\r\n",
        "import collections\r\n",
        "import os\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib as matplot\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import torch\r\n",
        "from IPython.display import Image  # for displaying images\r\n",
        "\r\n",
        "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwgpQGs8bnvw",
        "outputId": "e7836918-9e62-415e-f811-61d68753a45b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2018 Dataset"
      ],
      "metadata": {
        "id": "yInKxEXlbYNM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base_path = \"RDD_Dataset_2018/\"\r\n",
        "damageTypes=[\"D00\", \"D01\", \"D10\", \"D11\", \"D20\", \"D40\", \"D43\", \"D44\"]\r\n",
        "damageType_to_class = {\"D00\":0,\"D01\":1, \"D10\":2, \"D11\":3, \"D20\":4, \"D40\":5, \"D43\":6, \"D44\":7}\r\n",
        "# govs corresponds to municipality name.\r\n",
        "govs = [\"Adachi\", \"Chiba\", \"Ichihara\", \"Muroran\", \"Nagakute\", \"Numazu\", \"Sumida\"]"
      ],
      "outputs": [],
      "metadata": {
        "id": "HZKbCUc7bGoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!mkdir RDD_Dataset_2018_Yolo\r\n",
        "!mkdir RDD_Dataset_2018_Yolo/images\r\n",
        "!mkdir RDD_Dataset_2018_Yolo/labels\r\n",
        "!mkdir RDD_Dataset_2018_Yolo/images/train\r\n",
        "!mkdir RDD_Dataset_2018_Yolo/images/val\r\n",
        "!mkdir RDD_Dataset_2018_Yolo/labels/train\r\n",
        "!mkdir RDD_Dataset_2018_Yolo/labels/val"
      ],
      "outputs": [],
      "metadata": {
        "id": "4-shL5RFeiGI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PATH_IMGS = \"RDD_Dataset_2018_Yolo/images/\"\r\n",
        "PATH_LABELS = \"RDD_Dataset_2018_Yolo/labels/\""
      ],
      "outputs": [],
      "metadata": {
        "id": "uJTZfstsb_In"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move the val and train datasets in a good architecture for YoloV5"
      ],
      "metadata": {
        "id": "pjPgd6J6fiNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from shutil import copy\r\n",
        "for gov in govs:\r\n",
        "    file = open(base_path + gov + \"/ImageSets/Main/train.txt\")\r\n",
        "    for line in file :\r\n",
        "        img_name = line.rstrip('\\n')\r\n",
        "        img_path = base_path + gov + \"/JPEGImages/\" + img_name + \".jpg\"\r\n",
        "        train_path = PATH_IMGS + \"train/\"\r\n",
        "        copy(img_path,train_path)\r\n",
        "\r\n",
        "    file.close()\r\n",
        "    file = open(base_path + gov + \"/ImageSets/Main/val.txt\")\r\n",
        "    for line in file :\r\n",
        "        img_name = line.rstrip('\\n')\r\n",
        "        img_path = base_path + gov + \"/JPEGImages/\" + img_name + \".jpg\"\r\n",
        "        val_path = PATH_IMGS + \"val/\"\r\n",
        "        copy(img_path,val_path)\r\n",
        "\r\n",
        "    file.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "NDDW3_wTeacC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt the labels to YoloV5 format"
      ],
      "metadata": {
        "id": "gCbp7O40flU4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for gov in govs:\r\n",
        "    \r\n",
        "    for phase in ['train','val'] :\r\n",
        "\r\n",
        "        file_list = []\r\n",
        "\r\n",
        "        file_for_names = open(base_path + gov + \"/ImageSets/Main/{}.txt\".format(phase))\r\n",
        "        for line in file_for_names :\r\n",
        "            img_name = line.rstrip('\\n')\r\n",
        "            file_list.append(img_name)\r\n",
        "        file_for_names.close()\r\n",
        "\r\n",
        "        for file in file_list:\r\n",
        "            if file =='.DS_Store':\r\n",
        "                pass\r\n",
        "            else:\r\n",
        "                infile_xml = open(base_path + gov + '/Annotations/' + file+'.xml')\r\n",
        "                tree = ElementTree.parse(infile_xml)\r\n",
        "                root = tree.getroot()\r\n",
        "                file_txt = open(PATH_LABELS+phase+'/'+file+'.txt','a')\r\n",
        "                for obj in root.iter('object'):\r\n",
        "                    cls_name = obj.find('name').text\r\n",
        "\r\n",
        "                    if cls_name == 'D30' :\r\n",
        "                        pass\r\n",
        "                    else :\r\n",
        "\r\n",
        "                        xmlbox = obj.find('bndbox')\r\n",
        "                        xmin = int(xmlbox.find('xmin').text)\r\n",
        "                        xmax = int(xmlbox.find('xmax').text)\r\n",
        "                        ymin = int(xmlbox.find('ymin').text)\r\n",
        "                        ymax = int(xmlbox.find('ymax').text)\r\n",
        "\r\n",
        "                        x_center = 0.5*(xmin + xmax)\r\n",
        "                        y_center = 0.5*(ymin + ymax)\r\n",
        "                        width = xmax - xmin\r\n",
        "                        height = ymax - ymin\r\n",
        "                        \r\n",
        "                        x_center, y_center, width, height = round(x_center/600,5), round(y_center/600,5), round(width/600,5), round(height/600,5)\r\n",
        "\r\n",
        "                        class_number = damageType_to_class[cls_name]\r\n",
        "\r\n",
        "                        file_txt.write(str(class_number)+' '+str(x_center)+' '+str(y_center)+' '+str(width)+' '+str(height)+'\\n')\r\n",
        "                file_txt.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "WXLJQSFnfh0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2020 Dataset"
      ],
      "metadata": {
        "id": "sNyD693afZCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "nXQTldCphV9h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "import random\r\n",
        "from shutil import copy"
      ],
      "outputs": [],
      "metadata": {
        "id": "O8nOsuSgfbgW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "countries = ['Czech','India','Japan']\r\n",
        "base_path = \"RDD_Dataset_2020/\"\r\n",
        "damageType_to_class = {\"D00\":0,\"D10\":1, \"D20\":2, \"D40\":3}\r\n",
        "damageTypes = ['D00','D10','D20','D40']\r\n",
        "class_dict = {'D00':0,'D10':0,'D20':0,'D40':0}"
      ],
      "outputs": [],
      "metadata": {
        "id": "xx3QuSRyhW8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we only have the labels of the train dataset, we have to split the train set into two sets : the train set and the test/validation set\n",
        "We do that by random, "
      ],
      "metadata": {
        "id": "MisRVKZBhg5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "file_list = []\r\n",
        "for country in countries :\r\n",
        "    file_list_country = os.listdir('RDD_Dataset_2020/{}/images'.format(country))\r\n",
        "    random.shuffle(file_list_country)\r\n",
        "    file_list.append(file_list_country)\r\n",
        "    print(\"Number of images in \"+country+\" : \"+str(len(file_list_country)))"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D4hwMqBha6y",
        "outputId": "e5ed4bdf-025d-468e-c549-70fb97bbb900"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!mkdir RDD_Dataset_2020_Yolo\r\n",
        "!mkdir RDD_Dataset_2020_Yolo/images\r\n",
        "!mkdir RDD_Dataset_2020_Yolo/labels\r\n",
        "!mkdir RDD_Dataset_2020_Yolo/images/train\r\n",
        "!mkdir RDD_Dataset_2020_Yolo/images/val\r\n",
        "!mkdir RDD_Dataset_2020_Yolo/labels/train\r\n",
        "!mkdir RDD_Dataset_2020_Yolo/labels/val"
      ],
      "outputs": [],
      "metadata": {
        "id": "PF_JWAIUiXyV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "PROPORTION_TRAIN = 0.9 # Proportion of the images used for training\r\n",
        "PATH_IMGS = \"RDD_Dataset_2020_Yolo/images/\"\r\n",
        "PATH_LABELS = \"RDD_Dataset_2020_Yolo/labels/\""
      ],
      "outputs": [],
      "metadata": {
        "id": "9PidG1P6h7Nf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "file_list_train = []\r\n",
        "file_list_val = []\r\n",
        "for i in range(len(countries)) :\r\n",
        "    file_list_train.append(file_list[i][:int(PROPORTION_TRAIN*len(file_list[i]))])\r\n",
        "    file_list_val.append(file_list[i][int(PROPORTION_TRAIN*len(file_list[i])):])"
      ],
      "outputs": [],
      "metadata": {
        "id": "QSGbo3ZeihRV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "phases = ['train','val']\r\n",
        "file_list_train_val = [file_list_train,file_list_val]\r\n",
        "for (j,phase) in enumerate(phases) :\r\n",
        "    file_list_phase = file_list_train_val[j]\r\n",
        "    for (i,country) in enumerate(countries) :\r\n",
        "        file_list_country = file_list_phase[i]\r\n",
        "\r\n",
        "        ################################### FOR THE LABELS ###################################\r\n",
        "        for file in file_list_country:\r\n",
        "            file_name = file.rsplit('.')[0]\r\n",
        "            infile_xml = open(base_path + country + '/annotations/xmls/' + file_name +'.xml')\r\n",
        "            tree = ElementTree.parse(infile_xml)\r\n",
        "            root = tree.getroot()\r\n",
        "            file_txt = open(PATH_LABELS+phase+'/'+file_name+'.txt','w')\r\n",
        "\r\n",
        "            for obj in root.iter('size'):\r\n",
        "                img_height = int(obj.find('height').text)\r\n",
        "                img_width = int(obj.find('width').text)\r\n",
        "\r\n",
        "            nb_boxes_img = 0\r\n",
        "            for obj in root.iter('object'):\r\n",
        "                cls_name = obj.find('name').text\r\n",
        "                if cls_name not in damageTypes :\r\n",
        "                    pass\r\n",
        "                else :\r\n",
        "                    class_dict[cls_name]+=1\r\n",
        "                    nb_boxes_img += 1\r\n",
        "                    xmlbox = obj.find('bndbox')\r\n",
        "                    xmin = int(xmlbox.find('xmin').text)\r\n",
        "                    xmax = int(xmlbox.find('xmax').text)\r\n",
        "                    ymin = int(xmlbox.find('ymin').text)\r\n",
        "                    ymax = int(xmlbox.find('ymax').text)\r\n",
        "\r\n",
        "                    x_center = 0.5*(xmin + xmax)\r\n",
        "                    y_center = 0.5*(ymin + ymax)\r\n",
        "                    width = xmax - xmin\r\n",
        "                    height = ymax - ymin\r\n",
        "                    \r\n",
        "                    x_center, y_center, width, height = round(x_center/img_width,5), round(y_center/img_height,5), round(width/img_width,5), round(height/img_height,5)\r\n",
        "\r\n",
        "                    class_number = damageType_to_class[cls_name]\r\n",
        "\r\n",
        "                    file_txt.write(str(class_number)+' '+str(x_center)+' '+str(y_center)+' '+str(width)+' '+str(height)+'\\n')\r\n",
        "            file_txt.close()\r\n",
        "            ################################ FOR THE IMAGES ########################################\r\n",
        "            img_path = base_path + country + '/images/' + file\r\n",
        "            phase_path = PATH_IMGS+phase+'/'\r\n",
        "            copy(img_path,phase_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OFPwka6wituk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone YoloV5 GitHub repository to start training"
      ],
      "metadata": {
        "id": "aMZf_fzBk9aE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repository\r\n",
        "%cd yolov5\r\n",
        "# !git reset --hard '79af114' Uncomment if a new version of YoloV5 makes errors in the code\r\n",
        "%pip install -qr requirements.txt  # install dependencies\r\n",
        "import torch\r\n",
        "from IPython.display import Image, clear_output  # to display images\r\n",
        "\r\n",
        "clear_output()\r\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFOSMYh-lClf",
        "outputId": "71f3896b-3537-431c-db29-dba0c65bc1f0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!mv ../rdd2018.yaml data/\r\n",
        "!mv ../rdd2020.yaml data/"
      ],
      "outputs": [],
      "metadata": {
        "id": "dHFP_eyblYHT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Tensorboard  (optional)\r\n",
        "\r\n",
        "# %load_ext tensorboard\r\n",
        "# %tensorboard --logdir runs/train"
      ],
      "outputs": [],
      "metadata": {
        "id": "yd_JxyHom4Cp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Weights & Biases  (optional)\r\n",
        "\r\n",
        "# %pip install -q wandb\r\n",
        "# import wandb\r\n",
        "# wandb.login(key='xxx') # After registering to WandB you will have access to your key, that you cant put in the place of xxx"
      ],
      "outputs": [],
      "metadata": {
        "id": "w3ebPIqzm9e5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have any problem with training or testing with YoloV5, please refer to the [YoloV5 wiki](https://github.com/ultralytics/yolov5/wiki)"
      ],
      "metadata": {
        "id": "0MVIsZs-uQrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "kZcWMVSMqEh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every train run is saved in yolov5/runs/train/"
      ],
      "metadata": {
        "id": "EkTpMxNSxiud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with default hyperparameters and predefined weights"
      ],
      "metadata": {
        "id": "b9YRSn6XqOH_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python train.py --img 608 --batch 16 --epochs 15 --data rdd2018.yaml --weights 'yolov5x.pt'"
      ],
      "outputs": [],
      "metadata": {
        "id": "9MLBvz8wnHCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train from scratch using yolov5 architecture and randomly initialised weights"
      ],
      "metadata": {
        "id": "Iv8lPIBiWALo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python train.py --img 608 --batch 16 --epochs 15 --data rdd2018.yaml --weights ' ' -cfg 'yolov5x.yaml'"
      ],
      "outputs": [],
      "metadata": {
        "id": "lZeI3W_rV-8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use hyperparameter evolution to optimise them"
      ],
      "metadata": {
        "id": "aEA4gqKKqcLA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python train.py --img 608 --batch 16 --epochs 15 --data rdd2018.yaml --weights 'yolov5x.pt' --evolve 50"
      ],
      "outputs": [],
      "metadata": {
        "id": "C1JwQNUAnb1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "5lDlaV3kqHKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every test run is saved in yolov5/runs/test/"
      ],
      "metadata": {
        "id": "2PLNQyTAt4fY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test a neural network on a test dataset"
      ],
      "metadata": {
        "id": "PDotG1Meq4W9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python val.py --weights 'best_2018_608.pt' --data rdd2018.yaml --img 608"
      ],
      "outputs": [],
      "metadata": {
        "id": "cDZsM6Kcq_mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test a neural network on a test dataset with Test-Time Augmentation"
      ],
      "metadata": {
        "id": "YL-h1Xwnr9Vo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python val.py --weights 'best_2018_608.pt' --data rdd2018.yaml --img 608 --augment"
      ],
      "outputs": [],
      "metadata": {
        "id": "zBfZoydCr_b1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use model ensembling to make predictions on a test dataset"
      ],
      "metadata": {
        "id": "I_ePlwxFx7XN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python val.py --weights 'best_2018_608.pt' 'best_2018_448.pt' --data rdd2018.yaml --img 608 --augment"
      ],
      "outputs": [],
      "metadata": {
        "id": "wTAtC2QYVsLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect"
      ],
      "metadata": {
        "id": "Z53y5GHXxs66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is to produce images on which we can see the predictions"
      ],
      "metadata": {
        "id": "ze2jirpZ7urx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every detect run is saved in yolov5/runs/detect/"
      ],
      "metadata": {
        "id": "h8QksRaCVSZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!python detect.py --weights 'best_2018_608.pt' --data rdd2018.yaml --img 608 --augment"
      ],
      "outputs": [],
      "metadata": {
        "id": "Ku4GUhus7oRu"
      }
    }
  ]
}